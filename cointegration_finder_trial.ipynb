{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller, coint\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from itertools import combinations\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc56c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs(tickers, \n",
    "                           correlation_threshold=0.7,\n",
    "                           adf_pvalue_threshold=0.05,\n",
    "                           lookback_years=8,\n",
    "                           individual_adf_pvalue=0.05):\n",
    "    \"\"\"\n",
    "    Finds cointegrated pairs among a list of stock tickers.\n",
    "    \n",
    "    Cointegration Requirements (Engle-Granger):\n",
    "    - Each series is individually I(1) - non-stationary in levels\n",
    "    - Linear combination (spread/residuals) is I(0) - stationary\n",
    "    - ADF test on residuals from OLS regression\n",
    "    - Johansen test for validation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tickers : list\n",
    "        List of ticker symbols (20+)\n",
    "    correlation_threshold : float\n",
    "        Minimum correlation coefficient (default: 0.7)\n",
    "    adf_pvalue_threshold : float\n",
    "        Maximum p-value for ADF test on residuals (default: 0.05)\n",
    "    lookback_years : int\n",
    "        Years of historical data to analyze (default: 10)\n",
    "    individual_adf_pvalue : float\n",
    "        Maximum p-value for individual series to be I(1) (default: 0.05)\n",
    "        Series should FAIL to reject null (p > threshold) to be non-stationary\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Cointegrated pairs: [(ticker1, ticker2, stats_dict), ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Fetching {lookback_years} years of data for {len(tickers)} tickers...\")\n",
    "    \n",
    "    # Download historical data\n",
    "    end_date = datetime.now() -  timedelta(days=7*365) #train set 2010-2018\n",
    "    start_date = end_date - timedelta(days=lookback_years*365)\n",
    "    \n",
    "    data = yf.download(tickers, start=start_date, end=end_date, progress=False)['Close']\n",
    "    \n",
    "    # Handle single ticker case (returns Series instead of DataFrame)\n",
    "    if isinstance(data, pd.Series):\n",
    "        data = data.to_frame()\n",
    "    \n",
    "    # Drop tickers with insufficient data\n",
    "    min_data_points = int(lookback_years * 252 * 0.8)  # 80% of expected trading days\n",
    "    data = data.dropna(axis=1, thresh=min_data_points)\n",
    "    \n",
    "    available_tickers = data.columns.tolist()\n",
    "    print(f\"Valid tickers with sufficient data: {len(available_tickers)}\")\n",
    "    \n",
    "    if len(available_tickers) < 2:\n",
    "        print(\"Insufficient tickers with valid data.\")\n",
    "        return []\n",
    "    \n",
    "    # Drop rows with any NaN values for pairwise analysis\n",
    "    data = data.dropna()\n",
    "    \n",
    "    print(f\"Data shape: {data.shape} (rows: {data.shape[0]}, tickers: {data.shape[1]})\")\n",
    "    \n",
    "    print(\"\\nStep 1: Testing individual series for non-stationarity I(1)...\")\n",
    "    \n",
    "    # Test each series individually - they should be I(1) (non-stationary in levels)\n",
    "    stationary_tickers = []\n",
    "    non_stationary_tickers = []\n",
    "    \n",
    "    for ticker in available_tickers:\n",
    "        prices = data[ticker].values\n",
    "        adf_result = adfuller(prices, maxlag=1, regression='c')\n",
    "        adf_pvalue = adf_result[1]\n",
    "        \n",
    "        # For I(1): we want to FAIL to reject null hypothesis (non-stationary)\n",
    "        # So p-value should be > threshold (e.g., > 0.05)\n",
    "        if adf_pvalue > individual_adf_pvalue:\n",
    "            non_stationary_tickers.append(ticker)\n",
    "            print(f\"  ✓ {ticker}: Non-stationary (p={adf_pvalue:.4f}) - I(1)\")\n",
    "        else:\n",
    "            stationary_tickers.append(ticker)\n",
    "            print(f\"  ✗ {ticker}: Stationary (p={adf_pvalue:.4f}) - I(0), excluding\")\n",
    "    \n",
    "    print(f\"\\nValid I(1) tickers: {len(non_stationary_tickers)}\")\n",
    "    \n",
    "    if len(non_stationary_tickers) < 2:\n",
    "        print(\"Insufficient non-stationary tickers for cointegration analysis.\")\n",
    "        return []\n",
    "    \n",
    "    # Filter data to only include non-stationary tickers\n",
    "    data = data[non_stationary_tickers]\n",
    "    \n",
    "    print(\"\\nStep 2: Calculating correlation matrix...\")\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = data.corr()\n",
    "    \n",
    "    # Find pairs with high correlation (only among non-stationary tickers)\n",
    "    highly_correlated_pairs = []\n",
    "    for i, ticker1 in enumerate(non_stationary_tickers):\n",
    "        for ticker2 in non_stationary_tickers[i+1:]:\n",
    "            corr = correlation_matrix.loc[ticker1, ticker2]\n",
    "            if corr > correlation_threshold:\n",
    "                highly_correlated_pairs.append((ticker1, ticker2, corr))\n",
    "    \n",
    "    print(f\"Found {len(highly_correlated_pairs)} pairs with correlation > {correlation_threshold}\")\n",
    "    \n",
    "    if len(highly_correlated_pairs) == 0:\n",
    "        print(\"No highly correlated pairs found.\")\n",
    "        return []\n",
    "    \n",
    "    print(\"\\nStep 3: Testing for cointegration (Engle-Granger)...\")\n",
    "    cointegrated_pairs = []\n",
    "    \n",
    "    for ticker1, ticker2, corr in highly_correlated_pairs:\n",
    "        try:\n",
    "            prices1 = data[ticker1].values\n",
    "            prices2 = data[ticker2].values\n",
    "            \n",
    "            # Engle-Granger two-step procedure:\n",
    "            # Step 1: Run OLS regression on price levels: Y = α + β*X + ε\n",
    "            X = np.column_stack([np.ones(len(prices2)), prices2])\n",
    "            model = OLS(prices1, X).fit()\n",
    "            residuals = model.resid  # This is epsilon (the spread/error)\n",
    "            hedge_ratio = model.params[1]  # Beta coefficient\n",
    "            \n",
    "            # Step 2: Test if residuals (epsilon/spread) are stationary I(0)\n",
    "            # Apply Augmented Dickey-Fuller test to residuals\n",
    "            adf_result = adfuller(residuals, maxlag=1, regression='c')\n",
    "            adf_statistic = adf_result[0]\n",
    "            adf_pvalue = adf_result[1]\n",
    "            \n",
    "            # For cointegration: residuals must be stationary\n",
    "            # We want to REJECT null hypothesis (p-value < threshold)\n",
    "            if adf_pvalue < adf_pvalue_threshold:\n",
    "                # Perform Johansen test for additional validation\n",
    "                # Johansen test requires 2D array of both price series\n",
    "                price_matrix = np.column_stack([prices1, prices2])\n",
    "                \n",
    "                try:\n",
    "                    johansen_result = coint_johansen(price_matrix, det_order=0, k_ar_diff=1)\n",
    "                    # Check trace statistic against 95% critical value\n",
    "                    trace_stat = johansen_result.lr1[0]  # First eigenvalue trace stat\n",
    "                    critical_value_95 = johansen_result.cvt[0, 1]  # 95% critical value\n",
    "                    johansen_pass = trace_stat > critical_value_95\n",
    "                    \n",
    "                    if johansen_pass:\n",
    "                        stats = {\n",
    "                            'correlation': round(corr, 4),\n",
    "                            'hedge_ratio': round(hedge_ratio, 4),\n",
    "                            'adf_statistic': round(adf_statistic, 4),\n",
    "                            'adf_pvalue': round(adf_pvalue, 6),\n",
    "                            'johansen_trace': round(trace_stat, 4),\n",
    "                            'johansen_critical_95': round(critical_value_95, 4),\n",
    "                            'spread_mean': round(np.mean(residuals), 4),\n",
    "                            'spread_std': round(np.std(residuals), 4)\n",
    "                        }\n",
    "                        cointegrated_pairs.append((ticker1, ticker2, stats))\n",
    "                        print(f\"✓ {ticker1} - {ticker2}: COINTEGRATED\")\n",
    "                        print(f\"    Correlation: {corr:.4f} | Hedge Ratio: {hedge_ratio:.4f}\")\n",
    "                        print(f\"    ADF p-value: {adf_pvalue:.6f} (residuals stationary)\")\n",
    "                        print(f\"    Johansen: {trace_stat:.2f} > {critical_value_95:.2f}\")\n",
    "                    else:\n",
    "                        print(f\"✗ {ticker1} - {ticker2}: Failed Johansen test ({trace_stat:.2f} < {critical_value_95:.2f})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # If Johansen test fails, skip this pair\n",
    "                    print(f\"✗ {ticker1} - {ticker2}: Johansen test failed - {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ {ticker1} - {ticker2}: Error during testing - {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTS: Found {len(cointegrated_pairs)} cointegrated pairs\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return cointegrated_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ccffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    # Energy\n",
    "    \"XOM\", \"CVX\", \"BP\", \"SHEL\", \"COP\", \"TOT\", \"EOG\", \"SLB\", \"HAL\",\n",
    "    \n",
    "    # Financials\n",
    "    \"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\", \"MS\", \"AXP\", \"USB\", \"BK\",\n",
    "    \n",
    "    # Technology\n",
    "    \"AAPL\", \"MSFT\", \"GOOG\", \"META\", \"NVDA\", \"ADBE\", \"ORCL\", \"INTC\", \"CSCO\",\n",
    "    \n",
    "    # Consumer Staples\n",
    "    \"KO\", \"PEP\", \"PG\", \"CL\", \"KMB\", \"MDLZ\", \"KHC\", \"GIS\",\n",
    "    \n",
    "    # Consumer Discretionary\n",
    "    \"MCD\", \"SBUX\", \"NKE\", \"HD\", \"LOW\", \"TGT\", \"AMZN\", \"EBAY\",\n",
    "    \n",
    "    # Healthcare\n",
    "    \"JNJ\", \"PFE\", \"MRK\", \"ABBV\", \"BMY\", \"GILD\", \"AMGN\",\n",
    "    \n",
    "    # Industrials\n",
    "    \"CAT\", \"DE\", \"GE\", \"HON\", \"UPS\", \"FDX\", \"MMM\",\n",
    "    \n",
    "    # Utilities\n",
    "    \"NEE\", \"DUK\", \"SO\", \"D\", \"AEP\", \"EXC\",\n",
    "    \n",
    "    # Telecommunications\n",
    "    \"VZ\", \"T\", \"TMUS\",\n",
    "    \n",
    "    # Materials\n",
    "    \"LIN\", \"APD\", \"NUE\", \"SHW\", \"DD\",\n",
    "    \n",
    "    # ETFs / Index Trackers\n",
    "    \"SPY\", \"VOO\", \"QQQ\", \"DIA\", \"IWM\"\n",
    "]\n",
    "\n",
    "\n",
    "# Comprehensive economic sector classification\n",
    "SECTOR_CLASSIFICATION = {\n",
    "    # Energy\n",
    "    \"XOM\": \"Energy\", \"CVX\": \"Energy\", \"BP\": \"Energy\", \"SHEL\": \"Energy\",\n",
    "    \"COP\": \"Energy\", \"TOT\": \"Energy\", \"EOG\": \"Energy\", \"SLB\": \"Energy\", \"HAL\": \"Energy\",\n",
    "    \n",
    "    # Financials\n",
    "    \"JPM\": \"Financials\", \"BAC\": \"Financials\", \"WFC\": \"Financials\", \"C\": \"Financials\",\n",
    "    \"GS\": \"Financials\", \"MS\": \"Financials\", \"AXP\": \"Financials\", \"USB\": \"Financials\", \"BK\": \"Financials\",\n",
    "    \n",
    "    # Technology\n",
    "    \"AAPL\": \"Technology\", \"MSFT\": \"Technology\", \"GOOG\": \"Technology\", \"META\": \"Technology\",\n",
    "    \"NVDA\": \"Technology\", \"ADBE\": \"Technology\", \"ORCL\": \"Technology\", \"INTC\": \"Technology\", \"CSCO\": \"Technology\",\n",
    "    \n",
    "    # Consumer Staples\n",
    "    \"KO\": \"Consumer_Staples\", \"PEP\": \"Consumer_Staples\", \"PG\": \"Consumer_Staples\", \"CL\": \"Consumer_Staples\",\n",
    "    \"KMB\": \"Consumer_Staples\", \"MDLZ\": \"Consumer_Staples\", \"KHC\": \"Consumer_Staples\", \"GIS\": \"Consumer_Staples\",\n",
    "    \n",
    "    # Consumer Discretionary\n",
    "    \"MCD\": \"Consumer_Discretionary\", \"SBUX\": \"Consumer_Discretionary\", \"NKE\": \"Consumer_Discretionary\",\n",
    "    \"HD\": \"Consumer_Discretionary\", \"LOW\": \"Consumer_Discretionary\", \"TGT\": \"Consumer_Discretionary\",\n",
    "    \"AMZN\": \"Consumer_Discretionary\", \"EBAY\": \"Consumer_Discretionary\",\n",
    "    \n",
    "    # Healthcare\n",
    "    \"JNJ\": \"Healthcare\", \"PFE\": \"Healthcare\", \"MRK\": \"Healthcare\", \"ABBV\": \"Healthcare\",\n",
    "    \"BMY\": \"Healthcare\", \"GILD\": \"Healthcare\", \"AMGN\": \"Healthcare\",\n",
    "    \n",
    "    # Industrials\n",
    "    \"CAT\": \"Industrials\", \"DE\": \"Industrials\", \"GE\": \"Industrials\", \"HON\": \"Industrials\",\n",
    "    \"UPS\": \"Industrials\", \"FDX\": \"Industrials\", \"MMM\": \"Industrials\",\n",
    "    \n",
    "    # Utilities\n",
    "    \"NEE\": \"Utilities\", \"DUK\": \"Utilities\", \"SO\": \"Utilities\", \"D\": \"Utilities\",\n",
    "    \"AEP\": \"Utilities\", \"EXC\": \"Utilities\",\n",
    "    \n",
    "    # Telecommunications\n",
    "    \"VZ\": \"Telecommunications\", \"T\": \"Telecommunications\", \"TMUS\": \"Telecommunications\",\n",
    "    \n",
    "    # Materials\n",
    "    \"LIN\": \"Materials\", \"APD\": \"Materials\", \"NUE\": \"Materials\", \"SHW\": \"Materials\", \"DD\": \"Materials\",\n",
    "    \n",
    "    # ETFs / Index Trackers\n",
    "    \"SPY\": \"ETF\", \"VOO\": \"ETF\", \"QQQ\": \"ETF\", \"DIA\": \"ETF\", \"IWM\": \"ETF\",\n",
    "    \n",
    "    # International ADRs\n",
    "    \"RIO\": \"International\", \"BHP\": \"International\", \"NVS\": \"International\",\n",
    "    \"SONY\": \"International\", \"TM\": \"International\", \"SAP\": \"International\",\n",
    "    \"UL\": \"International\", \"UN\": \"International\", \"TD\": \"International\", \"RY\": \"International\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 9 years of data for 25 tickers...\n",
      "Valid tickers with sufficient data: 24\n",
      "Data shape: (2107, 24) (rows: 2107, tickers: 24)\n",
      "\n",
      "Step 1: Testing individual series for non-stationarity I(1)...\n",
      "  ✓ AAPL: Non-stationary (p=0.9844) - I(1)\n",
      "  ✓ AMZN: Non-stationary (p=0.9977) - I(1)\n",
      "  ✓ BAC: Non-stationary (p=0.9574) - I(1)\n",
      "  ✓ C: Non-stationary (p=0.7097) - I(1)\n",
      "  ✓ COP: Non-stationary (p=0.3683) - I(1)\n",
      "  ✓ CVX: Non-stationary (p=0.1857) - I(1)\n",
      "  ✓ GOOGL: Non-stationary (p=0.9149) - I(1)\n",
      "  ✓ GS: Non-stationary (p=0.7537) - I(1)\n",
      "  ✓ HD: Non-stationary (p=0.9689) - I(1)\n",
      "  ✓ JPM: Non-stationary (p=0.9788) - I(1)\n",
      "  ✓ KO: Non-stationary (p=0.5857) - I(1)\n",
      "  ✓ LOW: Non-stationary (p=0.9381) - I(1)\n",
      "  ✓ MCD: Non-stationary (p=0.9929) - I(1)\n",
      "  ✓ MS: Non-stationary (p=0.8426) - I(1)\n",
      "  ✓ MSFT: Non-stationary (p=0.9986) - I(1)\n",
      "  ✓ NKE: Non-stationary (p=0.9403) - I(1)\n",
      "  ✓ NVDA: Non-stationary (p=0.9880) - I(1)\n",
      "  ✓ PEP: Non-stationary (p=0.8702) - I(1)\n",
      "  ✓ SBUX: Non-stationary (p=0.8660) - I(1)\n",
      "  ✓ TGT: Non-stationary (p=0.7512) - I(1)\n",
      "  ✓ TSLA: Non-stationary (p=0.7557) - I(1)\n",
      "  ✓ WFC: Non-stationary (p=0.5962) - I(1)\n",
      "  ✓ WMT: Non-stationary (p=0.9213) - I(1)\n",
      "  ✗ XOM: Stationary (p=0.0175) - I(0), excluding\n",
      "\n",
      "Valid I(1) tickers: 23\n",
      "\n",
      "Step 2: Calculating correlation matrix...\n",
      "Found 234 pairs with correlation > 0.5\n",
      "\n",
      "Step 3: Testing for cointegration (Engle-Granger)...\n",
      "✗ AMZN - MSFT: Failed Johansen test (15.06 < 15.49)\n",
      "✓ BAC - C: COINTEGRATED\n",
      "    Correlation: 0.9646 | Hedge Ratio: 0.5574\n",
      "    ADF p-value: 0.012471 (residuals stationary)\n",
      "    Johansen: 18.19 > 15.49\n",
      "✗ BAC - GOOGL: Failed Johansen test (10.09 < 15.49)\n",
      "✗ BAC - JPM: Failed Johansen test (11.44 < 15.49)\n",
      "✗ BAC - MS: Failed Johansen test (12.99 < 15.49)\n",
      "✗ C - GS: Failed Johansen test (13.09 < 15.49)\n",
      "✗ C - MS: Failed Johansen test (13.19 < 15.49)\n",
      "✗ C - TSLA: Failed Johansen test (9.58 < 15.49)\n",
      "✗ CVX - GOOGL: Failed Johansen test (10.07 < 15.49)\n",
      "✗ CVX - HD: Failed Johansen test (10.64 < 15.49)\n",
      "✗ CVX - JPM: Failed Johansen test (14.21 < 15.49)\n",
      "✗ CVX - MCD: Failed Johansen test (13.43 < 15.49)\n",
      "✗ CVX - MS: Failed Johansen test (13.01 < 15.49)\n",
      "✓ CVX - MSFT: COINTEGRATED\n",
      "    Correlation: 0.7538 | Hedge Ratio: 0.3916\n",
      "    ADF p-value: 0.020758 (residuals stationary)\n",
      "    Johansen: 16.06 > 15.49\n",
      "✗ CVX - NVDA: Failed Johansen test (11.98 < 15.49)\n",
      "✗ CVX - TSLA: Failed Johansen test (12.26 < 15.49)\n",
      "✓ CVX - WMT: COINTEGRATED\n",
      "    Correlation: 0.8697 | Hedge Ratio: 2.4097\n",
      "    ADF p-value: 0.002611 (residuals stationary)\n",
      "    Johansen: 16.17 > 15.49\n",
      "✓ GOOGL - HD: COINTEGRATED\n",
      "    Correlation: 0.9838 | Hedge Ratio: 0.3173\n",
      "    ADF p-value: 0.000415 (residuals stationary)\n",
      "    Johansen: 19.94 > 15.49\n",
      "✗ GOOGL - JPM: Failed Johansen test (12.23 < 15.49)\n",
      "✗ GOOGL - KO: Failed Johansen test (13.98 < 15.49)\n",
      "✗ GOOGL - LOW: Failed Johansen test (9.91 < 15.49)\n",
      "✗ GOOGL - PEP: Failed Johansen test (10.25 < 15.49)\n",
      "✗ GS - MS: Failed Johansen test (15.26 < 15.49)\n",
      "✗ GS - TSLA: Failed Johansen test (9.26 < 15.49)\n",
      "✓ HD - KO: COINTEGRATED\n",
      "    Correlation: 0.9443 | Hedge Ratio: 7.9159\n",
      "    ADF p-value: 0.003694 (residuals stationary)\n",
      "    Johansen: 17.15 > 15.49\n",
      "✗ JPM - MSFT: Failed Johansen test (12.77 < 15.49)\n",
      "✓ KO - LOW: COINTEGRATED\n",
      "    Correlation: 0.9395 | Hedge Ratio: 0.2170\n",
      "    ADF p-value: 0.000918 (residuals stationary)\n",
      "    Johansen: 17.43 > 15.49\n",
      "✗ KO - MCD: Failed Johansen test (11.08 < 15.49)\n",
      "✗ KO - MSFT: Failed Johansen test (14.82 < 15.49)\n",
      "✗ KO - NKE: Failed Johansen test (13.19 < 15.49)\n",
      "✗ KO - PEP: Failed Johansen test (15.06 < 15.49)\n",
      "✗ KO - SBUX: Failed Johansen test (12.25 < 15.49)\n",
      "✗ KO - TSLA: Failed Johansen test (14.72 < 15.49)\n",
      "✗ KO - WFC: Failed Johansen test (10.73 < 15.49)\n",
      "✗ KO - WMT: Failed Johansen test (9.47 < 15.49)\n",
      "✓ LOW - NKE: COINTEGRATED\n",
      "    Correlation: 0.9778 | Hedge Ratio: 1.3413\n",
      "    ADF p-value: 0.001187 (residuals stationary)\n",
      "    Johansen: 17.61 > 15.49\n",
      "✗ LOW - PEP: Failed Johansen test (12.01 < 15.49)\n",
      "✗ MCD - MSFT: Failed Johansen test (14.10 < 15.49)\n",
      "✗ PEP - TSLA: Failed Johansen test (14.28 < 15.49)\n",
      "✗ PEP - WFC: Failed Johansen test (11.20 < 15.49)\n",
      "✓ TSLA - WFC: COINTEGRATED\n",
      "    Correlation: 0.9507 | Hedge Ratio: 0.7236\n",
      "    ADF p-value: 0.000285 (residuals stationary)\n",
      "    Johansen: 21.23 > 15.49\n",
      "\n",
      "============================================================\n",
      "RESULTS: Found 8 cointegrated pairs\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "pairs = find_cointegrated_pairs(\n",
    "        tickers, \n",
    "        correlation_threshold=0.7,\n",
    "        adf_pvalue_threshold=0.05,\n",
    "        lookback_years=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46dc44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_economically_related_pairs(pairs, sector_classification=None):\n",
    "    \"\"\"\n",
    "    Filters cointegrated pairs to keep only those with economic relationships.\n",
    "    \n",
    "    Economic relationship criteria:\n",
    "    - Same sub-sector (strongest relationship)\n",
    "    - Same broad sector with related business models\n",
    "    - Supply chain relationships\n",
    "    - Competitive dynamics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pairs : list\n",
    "        List of tuples from find_cointegrated_pairs()\n",
    "        Format: [(ticker1, ticker2, stats_dict), ...]\n",
    "    sector_classification : dict, optional\n",
    "        Custom sector mapping. If None, uses default SECTOR_CLASSIFICATION\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples\n",
    "        Filtered pairs with economic relationships\n",
    "        Format: [(ticker1, ticker2, stats_dict, relationship_type), ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    if sector_classification is None:\n",
    "        sector_classification = SECTOR_CLASSIFICATION\n",
    "    \n",
    "    economically_related_pairs = []\n",
    "    \n",
    "    print(f\"\\nFiltering {len(pairs)} cointegrated pairs for economic relationships...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for ticker1, ticker2, stats in pairs:\n",
    "        # Get sectors for both tickers\n",
    "        sector1 = sector_classification.get(ticker1, 'Unknown')\n",
    "        sector2 = sector_classification.get(ticker2, 'Unknown')\n",
    "        \n",
    "        # Skip if either ticker not classified\n",
    "        if sector1 == 'Unknown' or sector2 == 'Unknown':\n",
    "            print(f\"✗ {ticker1} - {ticker2}: Unclassified ticker(s)\")\n",
    "            print(f\"  {ticker1}: {sector1}\")\n",
    "            print(f\"  {ticker2}: {sector2}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract broad sector and sub-sector\n",
    "        broad1 = sector1.split(' - ')[0]\n",
    "        broad2 = sector2.split(' - ')[0]\n",
    "        \n",
    "        relationship_type = None\n",
    "        \n",
    "        # Check for exact sub-sector match (strongest relationship)\n",
    "        if sector1 == sector2:\n",
    "            relationship_type = \"Same Sub-Sector\"\n",
    "            economically_related_pairs.append((ticker1, ticker2, stats, relationship_type))\n",
    "            print(f\"✓ {ticker1} - {ticker2}: {relationship_type}\")\n",
    "            print(f\"  Sector: {sector1}\")\n",
    "            print(f\"  Correlation: {stats['correlation']:.4f} | Hedge Ratio: {stats['hedge_ratio']:.4f}\")\n",
    "            \n",
    "        # Check for same broad sector (related business models)\n",
    "        elif broad1 == broad2:\n",
    "            relationship_type = f\"Same Broad Sector ({broad1})\"\n",
    "            economically_related_pairs.append((ticker1, ticker2, stats, relationship_type))\n",
    "            print(f\"✓ {ticker1} - {ticker2}: {relationship_type}\")\n",
    "            print(f\"  {ticker1}: {sector1}\")\n",
    "            print(f\"  {ticker2}: {sector2}\")\n",
    "            print(f\"  Correlation: {stats['correlation']:.4f} | Hedge Ratio: {stats['hedge_ratio']:.4f}\")\n",
    "            \n",
    "        # Check for cross-sector economic relationships\n",
    "        else:\n",
    "            # Energy companies and energy-intensive industries\n",
    "            energy_intensive = ['Industrials - Airlines', 'Consumer - Traditional Automotive']\n",
    "            energy_producers = ['Energy - Oil & Gas Integrated', 'Energy - Oil & Gas Exploration']\n",
    "            \n",
    "            if (sector1 in energy_producers and sector2 in energy_intensive) or \\\n",
    "               (sector2 in energy_producers and sector1 in energy_intensive):\n",
    "                relationship_type = \"Supply Chain (Energy)\"\n",
    "                economically_related_pairs.append((ticker1, ticker2, stats, relationship_type))\n",
    "                print(f\"✓ {ticker1} - {ticker2}: {relationship_type}\")\n",
    "                print(f\"  {ticker1}: {sector1}\")\n",
    "                print(f\"  {ticker2}: {sector2}\")\n",
    "                \n",
    "            # Retail and consumer goods\n",
    "            elif (broad1 == 'Consumer' and broad2 == 'Consumer Staples') or \\\n",
    "                 (broad1 == 'Consumer Staples' and broad2 == 'Consumer'):\n",
    "                relationship_type = \"Related Consumer Sectors\"\n",
    "                economically_related_pairs.append((ticker1, ticker2, stats, relationship_type))\n",
    "                print(f\"✓ {ticker1} - {ticker2}: {relationship_type}\")\n",
    "                print(f\"  {ticker1}: {sector1}\")\n",
    "                print(f\"  {ticker2}: {sector2}\")\n",
    "                \n",
    "            # Tech ecosystem relationships\n",
    "            elif broad1 == 'Tech' and broad2 == 'Tech':\n",
    "                relationship_type = \"Tech Ecosystem\"\n",
    "                economically_related_pairs.append((ticker1, ticker2, stats, relationship_type))\n",
    "                print(f\"✓ {ticker1} - {ticker2}: {relationship_type}\")\n",
    "                print(f\"  {ticker1}: {sector1}\")\n",
    "                print(f\"  {ticker2}: {sector2}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"✗ {ticker1} - {ticker2}: No clear economic relationship\")\n",
    "                print(f\"  {ticker1}: {sector1}\")\n",
    "                print(f\"  {ticker2}: {sector2}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"RESULTS: {len(economically_related_pairs)} pairs with economic relationships\")\n",
    "    print(f\"Filtered out: {len(pairs) - len(economically_related_pairs)} spurious pairs\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return economically_related_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a420a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FILTERING FOR ECONOMIC RELATIONSHIPS\n",
      "================================================================================\n",
      "\n",
      "Filtering 2 cointegrated pairs for economic relationships...\n",
      "================================================================================\n",
      "✗ GOOGL - HD: No clear economic relationship\n",
      "  GOOGL: Tech - Internet & Advertising\n",
      "  HD: Consumer - Home Improvement\n",
      "✗ TSLA - WFC: No clear economic relationship\n",
      "  TSLA: Consumer - Electric Vehicles\n",
      "  WFC: Financial - Diversified Banks\n",
      "\n",
      "================================================================================\n",
      "RESULTS: 0 pairs with economic relationships\n",
      "Filtered out: 2 spurious pairs\n",
      "================================================================================\n",
      "\n",
      "No economically related cointegrated pairs found.\n"
     ]
    }
   ],
   "source": [
    "# Filter for economic relationships\n",
    "if pairs:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FILTERING FOR ECONOMIC RELATIONSHIPS\")\n",
    "    print(\"=\"*80)\n",
    "        \n",
    "    economically_related = filter_economically_related_pairs(pairs)\n",
    "        \n",
    "    # Display final results\n",
    "    if economically_related:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FINAL ECONOMICALLY RELATED COINTEGRATED PAIRS\")\n",
    "        print(\"=\"*80)\n",
    "        for ticker1, ticker2, stats, relationship in economically_related:\n",
    "            print(f\"\\n{ticker1} <-> {ticker2}\")\n",
    "            print(f\"  Relationship:    {relationship}\")\n",
    "            print(f\"  Correlation:     {stats['correlation']:.4f}\")\n",
    "            print(f\"  Hedge Ratio:     {stats['hedge_ratio']:.4f}\")\n",
    "            print(f\"  ADF p-value:     {stats['adf_pvalue']:.6f}\")\n",
    "            print(f\"  Spread Mean:     {stats['spread_mean']:.4f}\")\n",
    "            print(f\"  Spread Std:      {stats['spread_std']:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nNo economically related cointegrated pairs found.\")\n",
    "else:\n",
    "    print(\"\\nNo cointegrated pairs found with the given criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a7185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
